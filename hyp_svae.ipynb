{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hyp-svae.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernel_info": {
      "name": "python2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "nteract": {
      "version": "0.12.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {
        "height": "223px",
        "width": "193px"
      },
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Notebook contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "226px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HdurTVGudTJ"
      },
      "source": [
        "# Sequential Variational Autoencoders for Collaborative Filtering\n",
        "\n",
        "**Noveen Sachdeva, Giuseppe Manco, Ettore Ritacco, and Vikram Pudi** - *12th International ACM Conference on Web Search and Data Mining - WSDM '19*\n",
        "\n",
        "The notebook provides PyTorch code for the proposed model, \"SVAE\" along with the data preprocessing for the Movielens-1M dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwwdsgpkudTN"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6egUtl7ASuQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5089dffb-8289-46e9-d190-67ad81cfedcd"
      },
      "source": [
        "# download dataset\n",
        "!wget --no-check-certificate https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
        "!unzip -q  ml-1m.zip\n",
        "!pip install geoopt\n",
        "!git clone https://github.com/ilya-dubovitskii/hyrnn.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-28 11:37:32--  https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
            "WARNING: cannot verify files.grouplens.org's certificate, issued by ‘CN=InCommon RSA Server CA,OU=InCommon,O=Internet2,L=Ann Arbor,ST=MI,C=US’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5917549 (5.6M) [application/zip]\n",
            "Saving to: ‘ml-1m.zip’\n",
            "\n",
            "ml-1m.zip           100%[===================>]   5.64M  12.1MB/s    in 0.5s    \n",
            "\n",
            "2021-05-28 11:37:33 (12.1 MB/s) - ‘ml-1m.zip’ saved [5917549/5917549]\n",
            "\n",
            "Collecting geoopt\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/2e/8e0f92996e5c424ab265ca5e880e0296cae272eb25ad2087a5334815e588/geoopt-0.3.1-py3-none-any.whl (73kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from geoopt) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from geoopt) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->geoopt) (3.7.4.3)\n",
            "Installing collected packages: geoopt\n",
            "Successfully installed geoopt-0.3.1\n",
            "Cloning into 'hyrnn'...\n",
            "remote: Enumerating objects: 444, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 444 (delta 6), reused 10 (delta 3), pack-reused 429\u001b[K\n",
            "Receiving objects: 100% (444/444), 2.41 MiB | 5.76 MiB/s, done.\n",
            "Resolving deltas: 100% (213/213), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9vJJaWOudTN",
        "scrolled": true
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import json\n",
        "import pickle\n",
        "import random\n",
        "import functools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "\n",
        "from hyrnn import hyrnn\n",
        "import geoopt\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PxJl-3-udTO"
      },
      "source": [
        "# Hyper Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC-C18AzudTO"
      },
      "source": [
        "### change `DATA_DIR` to the location where the dataset sits\n",
        "### compatible datasets: ML-1M, Netflix-full\n",
        "\n",
        "hyper_params = {\n",
        "    'data_base': 'ml-1m/', # Don't remove the '/' at the end please :)\n",
        "    'project_name': 'colab',\n",
        "    # 'data_base': 'saved_data/netflix-full/',\n",
        "    # 'project_name': 'svae_netflix_full',\n",
        "    'model_file_name': '',\n",
        "    'log_file': '',\n",
        "    'history_split_test': [0.8, 0.2], # Part of test history to train on : Part of test history to test\n",
        "\n",
        "    'learning_rate': 0.01, # learning rate is required only if optimizer is adagrad\n",
        "    'optimizer': 'radam',\n",
        "    'weight_decay': float(5e-3),\n",
        "\n",
        "    'epochs': 25,\n",
        "    'batch_size': 1, # Needs to be 1, because we don't pack multiple sequences in the same batch\n",
        "    \n",
        "    'item_embed_size': 128,\n",
        "    'rnn_size': 100,\n",
        "    'hidden_size': 75,\n",
        "    'latent_size': 32,\n",
        "    'loss_type': 'next_k', # [predict_next, same, prefix, postfix, exp_decay, next_k]\n",
        "    'next_k': 4,\n",
        "\n",
        "    'number_users_to_keep': 1000000000,\n",
        "    'batch_log_interval': 1000,\n",
        "    'train_cp_users': 200,\n",
        "    'exploding_clip': 0.25,\n",
        "}\n",
        "\n",
        "file_name = '_optimizer_' + str(hyper_params['optimizer'])\n",
        "if hyper_params['optimizer'] == 'adagrad':\n",
        "    file_name += '_lr_' + str(hyper_params['learning_rate'])\n",
        "file_name += '_weight_decay_' + str(hyper_params['weight_decay'])\n",
        "file_name += '_loss_type_' + str(hyper_params['loss_type'])\n",
        "file_name += '_item_embed_size_' + str(hyper_params['item_embed_size'])\n",
        "file_name += '_rnn_size_' + str(hyper_params['rnn_size'])\n",
        "file_name += '_latent_size_' + str(hyper_params['latent_size'])\n",
        "\n",
        "log_file_root = \"saved_logs/\" # Don't remove the '/' at the end please :)\n",
        "model_file_root = \"saved_models/\" # Don't remove the '/' at the end please :)\n",
        "\n",
        "if not os.path.isdir(log_file_root): os.mkdir(log_file_root)\n",
        "if not os.path.isdir(model_file_root): os.mkdir(model_file_root)\n",
        "hyper_params['log_file'] = log_file_root + hyper_params['project_name'] + '_log' + file_name + '.txt'\n",
        "hyper_params['model_file_name'] = model_file_root + hyper_params['project_name'] + '_model' + file_name + '.pt'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj9EzJtiudTQ"
      },
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "**Courtesy:** Dawen Liang et al. \"*Variational autoencoders for collaborative filtering*\" published at WWW '18. <br>\n",
        "**Link:** https://github.com/dawenl/vae_cf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfUwqjCbudTS"
      },
      "source": [
        "DATA_DIR = hyper_params['data_base']\n",
        "pro_dir = os.path.join(DATA_DIR, 'pro_sg') # Path where preprocessed data will be saved\n",
        "hyper_params['data_base'] += 'pro_sg/'\n",
        "\n",
        "if not os.path.isdir(pro_dir): # We don't want to keep preprocessing every time we run the notebook\n",
        "    cols = ['userId', 'movieId', 'rating', 'timestamp']\n",
        "    dtypes = {'userId': 'int', 'movieId': 'int', 'timestamp': 'int', 'rating': 'int'}\n",
        "    raw_data = pd.read_csv(os.path.join(DATA_DIR, 'ratings.dat'), sep='::', names=cols, parse_dates=['timestamp'])\n",
        "\n",
        "    max_seq_len = 1000\n",
        "    n_heldout_users = 750 # If total users = N; train_users = N - 2*heldout; test_users & val_users = heldout\n",
        "\n",
        "    # binarize the data (only keep ratings >= 4)\n",
        "    raw_data = raw_data[raw_data['rating'] > 3.5]\n",
        "\n",
        "    # Remove users with greater than $max_seq_len number of watched movies\n",
        "    raw_data = raw_data.groupby([\"userId\"]).filter(lambda x: len(x) <= max_seq_len)\n",
        "\n",
        "    # Sort data values with the timestamp\n",
        "    raw_data = raw_data.groupby([\"userId\"]).apply(lambda x: x.sort_values([\"timestamp\"], ascending = True)).reset_index(drop=True)\n",
        "\n",
        "    raw_data.head()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHoqVddtudTS"
      },
      "source": [
        "def get_count(tp, id):\n",
        "    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n",
        "    count = playcount_groupbyid.size()\n",
        "    return count\n",
        "\n",
        "def filter_triplets(tp, min_uc=5, min_sc=0):\n",
        "    # Only keep the triplets for items which were clicked on by at least min_sc users. \n",
        "    if min_sc > 0:\n",
        "        itemcount = get_count(tp, 'movieId')\n",
        "        tp = tp[tp['movieId'].isin(itemcount[itemcount['size'] >= min_sc]['movieId'])]\n",
        "    \n",
        "    # Only keep the triplets for users who clicked on at least min_uc items\n",
        "    # After doing this, some of the items will have less than min_uc users, but should only be a small proportion\n",
        "    if min_uc > 0:\n",
        "        usercount = get_count(tp, 'userId')\n",
        "        tp = tp[tp['userId'].isin(usercount[usercount['size'] >= min_uc]['userId'])]\n",
        "    \n",
        "    # Update both usercount and itemcount after filtering\n",
        "    usercount, itemcount = get_count(tp, 'userId'), get_count(tp, 'movieId') \n",
        "    return tp, usercount, itemcount\n",
        "\n",
        "def split_train_test_proportion(data, test_prop=0.2):\n",
        "    data_grouped_by_user = data.groupby('userId')\n",
        "    tr_list, te_list = list(), list()\n",
        "\n",
        "    np.random.seed(98765)\n",
        "\n",
        "    for i, (uid, group) in enumerate(data_grouped_by_user):\n",
        "        n_items_u = len(group)\n",
        "#         print(f'uid:{uid}, n_items_u:{n_items_u}')\n",
        "        if n_items_u >= 5:\n",
        "            idx = np.zeros(n_items_u, dtype='bool')\n",
        "            # idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n",
        "            idx[int((1.0 - test_prop) * n_items_u):] = True\n",
        "            # print(idx)\n",
        "            \n",
        "            tr_list.append(group[np.logical_not(idx)])\n",
        "            te_list.append(group[idx])\n",
        "        else:\n",
        "            tr_list.append(group)\n",
        "\n",
        "        if i % 1000 == 0:\n",
        "            print(\"%d users sampled\" % i)\n",
        "            sys.stdout.flush()\n",
        "\n",
        "    data_tr = pd.concat(tr_list)\n",
        "    data_te = pd.concat(te_list)\n",
        "    \n",
        "    return data_tr, data_te\n",
        "\n",
        "def numerize(tp):\n",
        "    uid = list(map(lambda x: profile2id[x], tp['userId']))\n",
        "    sid = list(map(lambda x: show2id[x], tp['movieId']))\n",
        "    ra = list(map(lambda x: x, tp['rating']))\n",
        "    ret =  pd.DataFrame(data={'uid': uid, 'sid': sid, 'rating': ra}, columns=['uid', 'sid', 'rating'])\n",
        "    ret['rating'] = ret['rating'].apply(pd.to_numeric)\n",
        "    return ret"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eltjZbb-udTT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bec9d040-1737-4c0a-cf11-83bd0dc8104d"
      },
      "source": [
        "if not os.path.isdir(pro_dir): # We don't want to keep preprocessing every time we run the notebook\n",
        "\n",
        "    raw_data, user_activity, item_popularity = filter_triplets(raw_data)\n",
        "\n",
        "    sparsity = 1. * raw_data.shape[0] / (user_activity.shape[0] * item_popularity.shape[0])\n",
        "\n",
        "    print(\"After filtering, there are %d watching events from %d users and %d movies (sparsity: %.3f%%)\" % \n",
        "          (raw_data.shape[0], user_activity.shape[0], item_popularity.shape[0], sparsity * 100))\n",
        "\n",
        "    unique_uid = user_activity.index\n",
        "\n",
        "    np.random.seed(98765)\n",
        "    idx_perm = np.random.permutation(unique_uid.size)\n",
        "    unique_uid = unique_uid[idx_perm]\n",
        "\n",
        "    # create train/validation/test users\n",
        "    n_users = unique_uid.size\n",
        "\n",
        "    tr_users = unique_uid[:(n_users - n_heldout_users * 2)]\n",
        "    vd_users = unique_uid[(n_users - n_heldout_users * 2): (n_users - n_heldout_users)]\n",
        "    te_users = unique_uid[(n_users - n_heldout_users):]\n",
        "\n",
        "    train_plays = raw_data.loc[raw_data['userId'].isin(tr_users)]\n",
        "\n",
        "    unique_sid = pd.unique(train_plays['movieId'])\n",
        "\n",
        "    show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
        "    profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))\n",
        "\n",
        "    if not os.path.exists(pro_dir):\n",
        "        os.makedirs(pro_dir)\n",
        "\n",
        "    with open(os.path.join(pro_dir, 'unique_sid.txt'), 'w') as f:\n",
        "        for sid in unique_sid:\n",
        "            f.write('%s\\n' % sid)\n",
        "\n",
        "    vad_plays = raw_data.loc[raw_data['userId'].isin(vd_users)]\n",
        "    vad_plays = vad_plays.loc[vad_plays['movieId'].isin(unique_sid)]\n",
        "\n",
        "    vad_plays_tr, vad_plays_te = split_train_test_proportion(vad_plays)\n",
        "\n",
        "    test_plays = raw_data.loc[raw_data['userId'].isin(te_users)]\n",
        "    test_plays = test_plays.loc[test_plays['movieId'].isin(unique_sid)]\n",
        "\n",
        "    test_plays_tr, test_plays_te = split_train_test_proportion(test_plays)\n",
        "\n",
        "    train_data = numerize(train_plays)\n",
        "    train_data.to_csv(os.path.join(pro_dir, 'train.csv'), index=False)\n",
        "\n",
        "    vad_data_tr = numerize(vad_plays_tr)\n",
        "    vad_data_tr.to_csv(os.path.join(pro_dir, 'validation_tr.csv'), index=False)\n",
        "\n",
        "    vad_data_te = numerize(vad_plays_te)\n",
        "    vad_data_te.to_csv(os.path.join(pro_dir, 'validation_te.csv'), index=False)\n",
        "\n",
        "    test_data_tr = numerize(test_plays_tr)\n",
        "    test_data_tr.to_csv(os.path.join(pro_dir, 'test_tr.csv'), index=False)\n",
        "\n",
        "    test_data_te = numerize(test_plays_te)\n",
        "    test_data_te.to_csv(os.path.join(pro_dir, 'test_te.csv'), index=False)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After filtering, there are 571519 watching events from 6031 users and 3516 movies (sparsity: 2.695%)\n",
            "0 users sampled\n",
            "0 users sampled\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYS45kwmudTW"
      },
      "source": [
        "# Utlity functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVBuTonBudTW",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aa7a5d3-a12c-4457-a20e-f1d6aa124eb8"
      },
      "source": [
        "LongTensor = torch.LongTensor\n",
        "FloatTensor = torch.FloatTensor\n",
        "\n",
        "is_cuda_available = torch.cuda.is_available()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "if is_cuda_available: \n",
        "    print(\"Using CUDA...\\n\")\n",
        "    LongTensor = torch.cuda.LongTensor\n",
        "    FloatTensor = torch.cuda.FloatTensor\n",
        "    \n",
        "def save_obj(obj, name):\n",
        "    with open(name + '.pkl', 'wb') as f:\n",
        "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "def save_obj_json(obj, name):\n",
        "    with open(name + '.json', 'w') as f:\n",
        "        json.dump(obj, f)\n",
        "\n",
        "def load_obj(name):\n",
        "    with open(name + '.pkl', 'rb') as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "def load_obj_json(name):\n",
        "    with open(name + '.json', 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def file_write(log_file, s):\n",
        "    print(s)\n",
        "    f = open(log_file, 'a')\n",
        "    f.write(s+'\\n')\n",
        "    f.close()\n",
        "\n",
        "def clear_log_file(log_file):\n",
        "    f = open(log_file, 'w')\n",
        "    f.write('')\n",
        "    f.close()\n",
        "\n",
        "def pretty_print(h):\n",
        "    print(\"{\")\n",
        "    for key in h:\n",
        "        print(' ' * 4 + str(key) + ': ' + h[key])\n",
        "    print('}\\n')\n",
        "    \n",
        "def plot_len_vs_ndcg(len_to_ndcg_at_100_map):\n",
        "    \n",
        "    lens = list(len_to_ndcg_at_100_map.keys())\n",
        "    lens.sort()\n",
        "    X, Y = [], []\n",
        "    \n",
        "    for le in lens:\n",
        "        X.append(le)\n",
        "        ans = 0.0\n",
        "        for i in len_to_ndcg_at_100_map[le]: ans += float(i)\n",
        "        ans = ans / float(len(len_to_ndcg_at_100_map[le]))\n",
        "        Y.append(ans * 100.0)\n",
        "    \n",
        "    # Smoothening\n",
        "    Y_mine = []\n",
        "    prev_5 = []\n",
        "    for i in Y:\n",
        "        prev_5.append(i)\n",
        "        if len(prev_5) > 5: del prev_5[0]\n",
        "\n",
        "        temp = 0.0\n",
        "        for j in prev_5: temp += float(j)\n",
        "        temp = float(temp) / float(len(prev_5))\n",
        "        Y_mine.append(temp)\n",
        "    \n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.plot(X, Y_mine, label='SVAE')\n",
        "    plt.xlabel(\"Number of items in the fold-out set\")\n",
        "    plt.ylabel(\"Average NDCG@100\")\n",
        "    plt.title(hyper_params['project_name'])\n",
        "    if not os.path.isdir(\"saved_plots/\"): os.mkdir(\"saved_plots/\")\n",
        "    plt.savefig(\"saved_plots/seq_len_vs_ndcg_\" + hyper_params['project_name'] + \".pdf\")\n",
        "\n",
        "    leg = plt.legend(loc='best', ncol=2)\n",
        "    \n",
        "    plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using CUDA...\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_mEV8o-udTX"
      },
      "source": [
        "# Data Parsing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej90OlXFudTZ",
        "scrolled": true
      },
      "source": [
        "def load_data(hyper_params):\n",
        "    \n",
        "    file_write(hyper_params['log_file'], \"Started reading data file\")\n",
        "    \n",
        "    f = open(hyper_params['data_base'] + 'train.csv')\n",
        "    lines_train = f.readlines()[1:]\n",
        "    \n",
        "    f = open(hyper_params['data_base'] + 'validation_tr.csv')\n",
        "    lines_val_tr = f.readlines()[1:]\n",
        "    \n",
        "    f = open(hyper_params['data_base'] + 'validation_te.csv')\n",
        "    lines_val_te = f.readlines()[1:]\n",
        "    \n",
        "    f = open(hyper_params['data_base'] + 'test_tr.csv')\n",
        "    lines_test_tr = f.readlines()[1:]\n",
        "    \n",
        "    f = open(hyper_params['data_base'] + 'test_te.csv')\n",
        "    lines_test_te = f.readlines()[1:]\n",
        "    \n",
        "    unique_sid = list()\n",
        "    with open(hyper_params['data_base'] + 'unique_sid.txt', 'r') as f:\n",
        "        for line in f:\n",
        "            unique_sid.append(line.strip())\n",
        "    num_items = len(unique_sid)\n",
        "    \n",
        "    file_write(hyper_params['log_file'], \"Data Files loaded!\")\n",
        "\n",
        "    train_reader = DataReader(hyper_params, lines_train, None, num_items, True)\n",
        "    val_reader = DataReader(hyper_params, lines_val_tr, lines_val_te, num_items, False)\n",
        "    test_reader = DataReader(hyper_params, lines_test_tr, lines_test_te, num_items, False)\n",
        "\n",
        "    return train_reader, val_reader, test_reader, num_items\n",
        "\n",
        "class DataReader:\n",
        "    def __init__(self, hyper_params, a, b, num_items, is_training):\n",
        "        self.hyper_params = hyper_params\n",
        "        self.batch_size = hyper_params['batch_size']\n",
        "        \n",
        "        num_users = 0\n",
        "        min_user = 1000000000000000000000000 # Infinity\n",
        "        unique_users = set()\n",
        "        for line in a:\n",
        "            line = line.strip().split(\",\")\n",
        "            unique_users.add(int(line[0]))\n",
        "#             num_users = max(num_users, int(line[0]))\n",
        "#             min_user = min(min_user, int(line[0]))\n",
        "            \n",
        "#         num_users = num_users - min_user + 1\n",
        "        \n",
        "        self.num_users = len(unique_users)\n",
        "        self.id2idx = dict(zip(unique_users, range(self.num_users)))\n",
        "        self.min_user = min_user\n",
        "        self.num_items = num_items\n",
        "        \n",
        "        self.data_train = a\n",
        "        self.data_test = b\n",
        "        self.is_training = is_training\n",
        "        self.all_users = []\n",
        "        \n",
        "        self.prep()\n",
        "        self.number()\n",
        "\n",
        "    def prep(self):\n",
        "        print(f'num_users:{self.num_users}, len data_train:{len(self.data_train)}')\n",
        "        self.data = []\n",
        "        for i in range(self.num_users): self.data.append([])\n",
        "            \n",
        "        for i in tqdm(range(len(self.data_train))):\n",
        "            line = self.data_train[i]\n",
        "            line = line.strip().split(\",\")\n",
        "            self.data[self.id2idx[int(line[0])]].append([ int(line[1]), 1 ])\n",
        "        \n",
        "        if self.is_training == False:\n",
        "            self.data_te = []\n",
        "            for i in range(self.num_users): self.data_te.append([])\n",
        "                \n",
        "            for i in tqdm(range(len(self.data_test))):\n",
        "                line = self.data_test[i]\n",
        "                line = line.strip().split(\",\")\n",
        "                self.data_te[self.id2idx[int(line[0])]].append([ int(line[1]), 1 ])\n",
        "        \n",
        "    def number(self):\n",
        "        self.num_b = int(min(len(self.data), self.hyper_params['number_users_to_keep']) / self.batch_size)\n",
        "    \n",
        "    def iter(self):\n",
        "        users_done = 0\n",
        "\n",
        "        x_batch = []\n",
        "        \n",
        "        user_iterate_order = list(range(len(self.data)))\n",
        "        \n",
        "        # Randomly shuffle the training order\n",
        "        np.random.shuffle(user_iterate_order)\n",
        "        \n",
        "        for user in user_iterate_order:\n",
        "\n",
        "            if users_done > self.hyper_params['number_users_to_keep']: break\n",
        "            users_done += 1\n",
        "            \n",
        "            # TODO leave len(self.data[user]) - 1\n",
        "            y_batch_s = torch.zeros(self.batch_size, len(self.data[user]) - 1, self.num_items)\n",
        "            if is_cuda_available: y_batch_s = y_batch_s.cuda()\n",
        "            \n",
        "            if self.hyper_params['loss_type'] == 'predict_next':\n",
        "                for timestep in range(len(self.data[user]) - 1):\n",
        "                    y_batch_s[len(x_batch), timestep, :].scatter_(\n",
        "                        0, LongTensor([ i[0] for i in [ self.data[user][timestep + 1] ] ]), 1.0\n",
        "                    )\n",
        "                \n",
        "            elif self.hyper_params['loss_type'] == 'next_k':\n",
        "                for timestep in range(len(self.data[user]) - 1):\n",
        "                    y_batch_s[len(x_batch), timestep, :].scatter_(\n",
        "                        0, LongTensor([ i[0] for i in self.data[user][timestep + 1:][:self.hyper_params['next_k']] ]), 1.0\n",
        "                    )\n",
        "                \n",
        "            elif self.hyper_params['loss_type'] == 'postfix':\n",
        "                for timestep in range(len(self.data[user]) - 1):\n",
        "                    y_batch_s[len(x_batch), timestep, :].scatter_(\n",
        "                        0, LongTensor([ i[0] for i in self.data[user][timestep + 1:] ]), 1.0\n",
        "                    )\n",
        "            \n",
        "            x_batch.append([ i[0] for i in self.data[user][:-1] ])\n",
        "            \n",
        "            if len(x_batch) == self.batch_size: # batch_size always = 1\n",
        "            \n",
        "                yield Variable(LongTensor(x_batch)), Variable(y_batch_s, requires_grad=False)\n",
        "                x_batch = []\n",
        "\n",
        "    def iter_eval(self):\n",
        "\n",
        "        x_batch = []\n",
        "        test_movies, test_movies_r = [], []\n",
        "        \n",
        "        users_done = 0\n",
        "        \n",
        "        for user in range(len(self.data)):\n",
        "            \n",
        "            users_done += 1\n",
        "            if users_done > self.hyper_params['number_users_to_keep']: break\n",
        "            \n",
        "            if self.is_training == True: \n",
        "                split = float(self.hyper_params['history_split_test'][0])\n",
        "                base_predictions_on = self.data[user][:int(split * len(self.data[user]))]\n",
        "                heldout_movies = self.data[user][int(split * len(self.data[user])):]\n",
        "            else:\n",
        "                base_predictions_on = self.data[user]\n",
        "                heldout_movies = self.data_te[user]\n",
        "            \n",
        "            y_batch_s = torch.zeros(self.batch_size, len(base_predictions_on) - 1, self.num_items).to(device)\n",
        "            \n",
        "            if self.hyper_params['loss_type'] == 'predict_next':\n",
        "                for timestep in range(len(base_predictions_on) - 1):\n",
        "                    y_batch_s[len(x_batch), timestep, :].scatter_(\n",
        "                        0, LongTensor([ i[0] for i in [ base_predictions_on[timestep + 1] ] ]), 1.0\n",
        "                    )\n",
        "                \n",
        "            elif self.hyper_params['loss_type'] == 'next_k':\n",
        "                for timestep in range(len(base_predictions_on) - 1):\n",
        "                    y_batch_s[len(x_batch), timestep, :].scatter_(\n",
        "                        0, LongTensor([ i[0] for i in base_predictions_on[timestep + 1:][:self.hyper_params['next_k']] ]), 1.0\n",
        "                    )\n",
        "                \n",
        "            elif self.hyper_params['loss_type'] == 'postfix':\n",
        "                for timestep in range(len(base_predictions_on) - 1):\n",
        "                    y_batch_s[len(x_batch), timestep, :].scatter_(\n",
        "                        0, LongTensor([ i[0] for i in base_predictions_on[timestep + 1:] ]), 1.0\n",
        "                    )\n",
        "            \n",
        "            test_movies.append([ i[0] for i in heldout_movies ])\n",
        "            test_movies_r.append([ i[1] for i in heldout_movies ])\n",
        "            x_batch.append([ i[0] for i in base_predictions_on[:-1] ])\n",
        "            \n",
        "            if len(x_batch) == self.batch_size: # batch_size always = 1\n",
        "                \n",
        "                yield Variable(LongTensor(x_batch)), Variable(y_batch_s, requires_grad=False), test_movies, test_movies_r\n",
        "                x_batch = []\n",
        "                test_movies, test_movies_r = [], []"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC50ZWKzudTb"
      },
      "source": [
        "# Evaluation Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QNkvwdOudTb",
        "scrolled": true
      },
      "source": [
        "def evaluate(model, criterion, reader, hyper_params, is_train_set):\n",
        "    model.eval()\n",
        "\n",
        "    metrics = {}\n",
        "    metrics['loss'] = 0.0\n",
        "    Ks = [10, 100]\n",
        "    for k in Ks: \n",
        "        metrics['NDCG@' + str(k)] = 0.0\n",
        "        metrics['Rec@' + str(k)] = 0.0\n",
        "        metrics['Prec@' + str(k)] = 0.0\n",
        "\n",
        "    batch = 0\n",
        "    total_users = 0.0\n",
        "    \n",
        "    # For plotting the results (seq length vs. NDCG@100)\n",
        "    len_to_ndcg_at_100_map = {}\n",
        "\n",
        "    for x, y_s, test_movies, test_movies_r in reader.iter_eval():\n",
        "        batch += 1\n",
        "        if is_train_set == True and batch > hyper_params['train_cp_users']: break\n",
        "\n",
        "        decoder_output, z_mean, z_log_sigma = model(x)\n",
        "        \n",
        "        metrics['loss'] += criterion(decoder_output, z_mean, z_log_sigma, y_s, 0.2).data.item()\n",
        "        \n",
        "        # Making the logits of previous items in the sequence to be \"- infinity\"\n",
        "        decoder_output = decoder_output.data\n",
        "        x_scattered = torch.zeros(decoder_output.shape[0], decoder_output.shape[2])\n",
        "        if is_cuda_available: x_scattered = x_scattered.cuda()\n",
        "        x_scattered[0, :].scatter_(0, x[0].data, 1.0)\n",
        "        last_predictions = decoder_output[:, -1, :] - (torch.abs(decoder_output[:, -1, :] * x_scattered) * 100000000)\n",
        "        \n",
        "        for batch_num in range(last_predictions.shape[0]): # batch_num is ideally only 0, since batch_size is enforced to be always 1\n",
        "            predicted_scores = last_predictions[batch_num]\n",
        "            actual_movies_watched = test_movies[batch_num]\n",
        "            actual_movies_ratings = test_movies_r[batch_num]\n",
        "                    \n",
        "            # Calculate NDCG\n",
        "            _, argsorted = torch.sort(-1.0 * predicted_scores)\n",
        "            for k in Ks:\n",
        "                best, now_at, dcg, hits = 0.0, 0.0, 0.0, 0.0\n",
        "                \n",
        "                rec_list = list(argsorted[:k].cpu().numpy())\n",
        "                for m in range(len(actual_movies_watched)):\n",
        "                    movie = actual_movies_watched[m]\n",
        "                    now_at += 1.0\n",
        "                    if now_at <= k: best += 1.0 / float(np.log2(now_at + 1))\n",
        "                    \n",
        "                    if movie not in rec_list: continue\n",
        "                    hits += 1.0\n",
        "                    dcg += 1.0 / float(np.log2(float(rec_list.index(movie) + 2)))\n",
        "                \n",
        "                metrics['NDCG@' + str(k)] += float(dcg) / float(best)\n",
        "                metrics['Rec@' + str(k)] += float(hits) / float(len(actual_movies_watched))\n",
        "                metrics['Prec@' + str(k)] += float(hits) / float(k)\n",
        "                \n",
        "                # Only for plotting the graph (seq length vs. NDCG@100)\n",
        "                if k == 100:\n",
        "                    seq_len = int(len(actual_movies_watched)) + int(x[batch_num].shape[0]) + 1\n",
        "                    if seq_len not in len_to_ndcg_at_100_map: len_to_ndcg_at_100_map[seq_len] = []\n",
        "                    len_to_ndcg_at_100_map[seq_len].append(float(dcg) / float(best))\n",
        "                \n",
        "            total_users += 1.0\n",
        "    \n",
        "    metrics['loss'] = float(metrics['loss']) / float(batch)\n",
        "    metrics['loss'] = round(metrics['loss'], 4)\n",
        "    \n",
        "    for k in Ks:\n",
        "        metrics['NDCG@' + str(k)] = round((100.0 * metrics['NDCG@' + str(k)]) / float(total_users), 4)\n",
        "        metrics['Rec@' + str(k)] = round((100.0 * metrics['Rec@' + str(k)]) / float(total_users), 4)\n",
        "        metrics['Prec@' + str(k)] = round((100.0 * metrics['Prec@' + str(k)]) / float(total_users), 4)\n",
        "        \n",
        "    return metrics, len_to_ndcg_at_100_map"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuC72r8KudTc"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zB13L-BzFcXs"
      },
      "source": [
        "curvature = 1.0"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sL5nGc-YudTc",
        "scrolled": true
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, hyper_params):\n",
        "        super(Encoder, self).__init__()\n",
        "        \n",
        "        self.linear1 = hyrnn.MobiusLinear(\n",
        "            hyper_params['rnn_size'], hyper_params['hidden_size'], c=curvature, hyperbolic_input=True\n",
        "        )\n",
        "\n",
        "        nn.init.xavier_normal(self.linear1.weight)\n",
        "        self.activation = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hyper_params):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.linear1 = hyrnn.MobiusLinear(hyper_params['latent_size'],\n",
        "                                          hyper_params['hidden_size'], c=curvature)\n",
        "        self.linear2 = hyrnn.MobiusLinear(hyper_params['hidden_size'],\n",
        "                                          hyper_params['total_items'], c=curvature)\n",
        "        nn.init.xavier_normal(self.linear1.weight)\n",
        "        nn.init.xavier_normal(self.linear2.weight)\n",
        "        self.activation = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.linear2(x)\n",
        "        return x\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, hyper_params):\n",
        "        super(Model, self).__init__()\n",
        "        self.hyper_params = hyper_params\n",
        "        \n",
        "        self.encoder = Encoder(hyper_params)\n",
        "        self.decoder = Decoder(hyper_params)\n",
        "        \n",
        "        # Since we don't need padding, our vocabulary size = \"hyper_params['total_items']\" and not \"hyper_params['total_items'] + 1\"\n",
        "        self.item_embed = hyrnn.LookupEmbedding(hyper_params['total_items'],\n",
        "                                                hyper_params['item_embed_size'],\n",
        "                                                manifold=geoopt.PoincareBall(c=curvature))\n",
        "        \n",
        "        self.gru = nn.GRU(\n",
        "            hyper_params['item_embed_size'], hyper_params['rnn_size'], \n",
        "            batch_first = True, num_layers = 1\n",
        "        )\n",
        "        \n",
        "        self.hygru = hyrnn.MobiusGRU(input_size=hyper_params['item_embed_size'],\n",
        "                                    hidden_size=hyper_params['rnn_size'],\n",
        "                                    num_layers = 1,\n",
        "                                    hyperbolic_input=False,\n",
        "                                    hyperbolic_hidden_state0=True,\n",
        "                                    c=curvature)\n",
        "        self.linear1 = hyrnn.MobiusLinear(hyper_params['hidden_size'], 2 * hyper_params['latent_size'], c=curvature)\n",
        "        nn.init.xavier_normal(self.linear1.weight)\n",
        "        \n",
        "        self.tanh = nn.Tanh()\n",
        "        \n",
        "    def sample_latent(self, h_enc):\n",
        "        \"\"\"\n",
        "        Return the latent normal sample z ~ N(mu, sigma^2)\n",
        "        \"\"\"\n",
        "        temp_out = self.linear1(h_enc)\n",
        "        \n",
        "        mu = temp_out[:, :self.hyper_params['latent_size']]\n",
        "        log_sigma = temp_out[:, self.hyper_params['latent_size']:]\n",
        "        \n",
        "        sigma = torch.exp(log_sigma)\n",
        "        std_z = torch.from_numpy(np.random.normal(0, 1, size=sigma.size())).float()\n",
        "        if is_cuda_available: std_z = std_z.cuda()\n",
        "\n",
        "        self.z_mean = mu\n",
        "        self.z_log_sigma = log_sigma\n",
        "\n",
        "        return mu + sigma * Variable(std_z, requires_grad=False)  # Reparameterization trick\n",
        "\n",
        "    def forward(self, x):\n",
        "        in_shape = x.shape                                      # [bsz x seq_len] = [1 x seq_len]\n",
        "        x = x.view(-1)                                          # [seq_len]\n",
        "        \n",
        "        x = self.item_embed(x)                                  # [seq_len x embed_size]\n",
        "        x = x.view(in_shape[0], in_shape[1], -1)                # [1 x seq_len x embed_size]\n",
        "        \n",
        "        rnn_out, _ = self.hygru(x)                                # [1 x seq_len x rnn_size]\n",
        "        rnn_out = rnn_out.view(in_shape[0] * in_shape[1], -1)   # [seq_len x rnn_size]\n",
        "        \n",
        "        enc_out = self.encoder(rnn_out)                         # [seq_len x hidden_size]\n",
        "        sampled_z = self.sample_latent(enc_out)                 # [seq_len x latent_size]\n",
        "        \n",
        "        dec_out = self.decoder(sampled_z)                       # [seq_len x total_items]\n",
        "        dec_out = dec_out.view(in_shape[0], in_shape[1], -1)    # [1 x seq_len x total_items]\n",
        "                              \n",
        "        return dec_out, self.z_mean, self.z_log_sigma"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cySNGvVnudTd"
      },
      "source": [
        "# Custom loss\n",
        "\n",
        "$$ Loss \\; = \\; \\sum_{u \\in U} Loss_u $$ <br>\n",
        "$$ Loss_u \\; = \\; \\beta * KL( \\, \\phi(z \\vert x) \\, \\Vert \\, {\\rm I\\!N(0, I)} \\, ) \\; - \\; log( \\, P_{\\phi}(g_{\\theta}(x)) \\, ) $$ <br>\n",
        "$ g_{\\theta}(.)$ is the encoder ; $P_{\\phi}(.)$ is the decoded distribution; $ \\beta $ is the anneal factor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqHulS3cudTd",
        "scrolled": true
      },
      "source": [
        "class VAELoss(torch.nn.Module):\n",
        "    def __init__(self, hyper_params):\n",
        "        super(VAELoss,self).__init__()\n",
        "        self.hyper_params = hyper_params\n",
        "\n",
        "    def forward(self, decoder_output, mu_q, logvar_q, y_true_s, anneal):\n",
        "        # Calculate KL Divergence loss\n",
        "        kld = torch.mean(torch.sum(0.5 * (-logvar_q + torch.exp(logvar_q) + mu_q**2 - 1), -1))\n",
        "    \n",
        "        # Calculate Likelihood\n",
        "        dec_shape = decoder_output.shape # [batch_size x seq_len x total_items] = [1 x seq_len x total_items]\n",
        "\n",
        "        decoder_output = F.log_softmax(decoder_output, -1)\n",
        "        num_ones = float(torch.sum(y_true_s[0, 0]))\n",
        "        \n",
        "        likelihood = torch.sum(\n",
        "            -1.0 * y_true_s.view(dec_shape[0] * dec_shape[1], -1) * \\\n",
        "            decoder_output.view(dec_shape[0] * dec_shape[1], -1)\n",
        "        ) / (float(self.hyper_params['batch_size']) * num_ones)\n",
        "        \n",
        "        final = (anneal * kld) + (likelihood)\n",
        "        \n",
        "        return final"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8ATPl01udTf"
      },
      "source": [
        "# Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oqU5SYmludTf",
        "scrolled": false,
        "outputId": "dc25b33f-fc0b-4d10-a1a0-306dcb99574d"
      },
      "source": [
        "def train(reader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    start_time = time.time()\n",
        "    batch = 0\n",
        "    batch_limit = int(train_reader.num_b)\n",
        "    total_anneal_steps = 200000\n",
        "    anneal = 0.0\n",
        "    update_count = 0.0\n",
        "    anneal_cap = 0.2\n",
        "\n",
        "    for x, y_s in reader.iter():\n",
        "        batch += 1\n",
        "        \n",
        "        # Empty the gradients\n",
        "        model.zero_grad()\n",
        "        optimizer.zero_grad()\n",
        "    \n",
        "        # Forward pass\n",
        "        decoder_output, z_mean, z_log_sigma = model(x)\n",
        "        \n",
        "        # Backward pass\n",
        "        loss = criterion(decoder_output, z_mean, z_log_sigma, y_s, anneal)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.data\n",
        "        \n",
        "        # Anneal logic\n",
        "        if total_anneal_steps > 0:\n",
        "            anneal = min(anneal_cap, 1. * update_count / total_anneal_steps)\n",
        "        else:\n",
        "            anneal = anneal_cap\n",
        "        update_count += 1.0\n",
        "        \n",
        "        # Logging mechanism\n",
        "        if (batch % hyper_params['batch_log_interval'] == 0 and batch > 0) or batch == batch_limit:\n",
        "            div = hyper_params['batch_log_interval']\n",
        "            if batch == batch_limit: div = (batch_limit % hyper_params['batch_log_interval']) - 1\n",
        "            if div <= 0: div = 1\n",
        "\n",
        "            cur_loss = (total_loss.item() / div)\n",
        "            elapsed = time.time() - start_time\n",
        "            \n",
        "            ss = '| epoch {:3d} | {:5d}/{:5d} batches | ms/batch {:5.2f} | loss {:5.4f}'.format(\n",
        "                    epoch, batch, batch_limit, (elapsed * 1000) / div, cur_loss\n",
        "            )\n",
        "            \n",
        "            file_write(hyper_params['log_file'], ss)\n",
        "\n",
        "            total_loss = 0\n",
        "            start_time = time.time()\n",
        "\n",
        "# Train It..\n",
        "train_reader, val_reader, test_reader, total_items = load_data(hyper_params)\n",
        "hyper_params['total_items'] = total_items\n",
        "hyper_params['testing_batch_limit'] = test_reader.num_b\n",
        "\n",
        "file_write(hyper_params['log_file'], \"\\n\\nSimulation run on: \" + str(dt.datetime.now()) + \"\\n\\n\")\n",
        "file_write(hyper_params['log_file'], \"Data reading complete!\")\n",
        "file_write(hyper_params['log_file'], \"Number of train batches: {:4d}\".format(train_reader.num_b))\n",
        "file_write(hyper_params['log_file'], \"Number of validation batches: {:4d}\".format(val_reader.num_b))\n",
        "file_write(hyper_params['log_file'], \"Number of test batches: {:4d}\".format(test_reader.num_b))\n",
        "file_write(hyper_params['log_file'], \"Total Items: \" + str(total_items) + \"\\n\")\n",
        "\n",
        "model = Model(hyper_params)\n",
        "if is_cuda_available: \n",
        "    print(('SENDING MODEL TO CUDA...'))\n",
        "    model.cuda()\n",
        "\n",
        "criterion = VAELoss(hyper_params)\n",
        "\n",
        "if hyper_params['optimizer'] == 'adagrad':\n",
        "    optimizer = torch.optim.Adagrad(\n",
        "        model.parameters(), weight_decay=hyper_params['weight_decay'], lr = hyper_params['learning_rate']\n",
        "    )\n",
        "elif hyper_params['optimizer'] == 'adadelta':\n",
        "    optimizer = torch.optim.Adadelta(\n",
        "        model.parameters(), weight_decay=hyper_params['weight_decay']\n",
        "    )\n",
        "elif hyper_params['optimizer'] == 'adam':\n",
        "    optimizer = torch.optim.Adam(\n",
        "        model.parameters(), weight_decay=hyper_params['weight_decay']\n",
        "    )\n",
        "elif hyper_params['optimizer'] == 'rmsprop':\n",
        "    optimizer = torch.optim.RMSprop(\n",
        "        model.parameters(), weight_decay=hyper_params['weight_decay']\n",
        "    )\n",
        "elif hyper_params['optimizer'] == 'radam':\n",
        "    optimizer = geoopt.optim.RiemannianAdam(\n",
        "        model.parameters(), weight_decay=hyper_params['weight_decay']\n",
        "    )\n",
        "\n",
        "file_write(hyper_params['log_file'], str(model))\n",
        "file_write(hyper_params['log_file'], \"\\nModel Built!\\nStarting Training...\\n\")\n",
        "\n",
        "best_val_ndcg = None\n",
        "\n",
        "try:\n",
        "    for epoch in range(1, hyper_params['epochs'] + 1):\n",
        "        epoch_start_time = time.time()\n",
        "        \n",
        "        train(train_reader)\n",
        "        \n",
        "        # Calulating the metrics on the train set\n",
        "        metrics, _ = evaluate(model, criterion, train_reader, hyper_params, True)\n",
        "        string = \"\"\n",
        "        for m in metrics: string += \" | \" + m + ' = ' + str(metrics[m])\n",
        "        string += ' (TRAIN)'\n",
        "    \n",
        "        # Calulating the metrics on the validation set\n",
        "        metrics, _ = evaluate(model, criterion, val_reader, hyper_params, False)\n",
        "        string2 = \"\"\n",
        "        for m in metrics: string2 += \" | \" + m + ' = ' + str(metrics[m])\n",
        "        string2 += ' (VAL)'\n",
        "\n",
        "        ss  = '-' * 89\n",
        "        ss += '\\n| end of epoch {:3d} | time: {:5.2f}s'.format(epoch, (time.time() - epoch_start_time))\n",
        "        ss += string\n",
        "        ss += '\\n'\n",
        "        ss += '-' * 89\n",
        "        ss += '\\n| end of epoch {:3d} | time: {:5.2f}s'.format(epoch, (time.time() - epoch_start_time))\n",
        "        ss += string2\n",
        "        ss += '\\n'\n",
        "        ss += '-' * 89\n",
        "        file_write(hyper_params['log_file'], ss)\n",
        "        \n",
        "        if not best_val_ndcg or metrics['NDCG@100'] >= best_val_ndcg:\n",
        "            with open(hyper_params['model_file_name'], 'wb') as f:\n",
        "                torch.save(model, f)\n",
        "            best_val_ndcg = metrics['NDCG@100']\n",
        "\n",
        "except KeyboardInterrupt: print('Exiting from training early')\n",
        "\n",
        "# Plot Traning graph\n",
        "f = open(model.hyper_params['log_file'])\n",
        "lines = f.readlines()\n",
        "lines.reverse()\n",
        "\n",
        "train = []\n",
        "test = []\n",
        "\n",
        "for line in lines:\n",
        "    if line[:10] == 'Simulation' and len(train) > 1:\n",
        "        break\n",
        "    elif line[:10] == 'Simulation' and len(train) <= 1:\n",
        "        train, test = [], []\n",
        "        \n",
        "    if line[2:5] == 'end' and line[-5:-2] == 'VAL':\n",
        "        test.append(line.strip().split(\"|\"))\n",
        "    elif line[2:5] == 'end' and line[-7:-2] == 'TRAIN':\n",
        "        train.append(line.strip().split(\"|\"))\n",
        "\n",
        "train.reverse()\n",
        "test.reverse()\n",
        "\n",
        "train_ndcg = []\n",
        "test_ndcg = []\n",
        "test_loss, train_loss = [], []\n",
        "\n",
        "for i in train:\n",
        "    for metric in i:\n",
        "        if metric.split(\"=\")[0] == \" NDCG@100 \":\n",
        "            train_ndcg.append(float(metric.split('=')[1].split(' ')[1]))\n",
        "        if metric.split(\"=\")[0] == \" loss \":\n",
        "            train_loss.append(float(metric.split(\"=\")[1].split(' ')[1]))\n",
        "\n",
        "total, avg_runtime = 0.0, 0.0\n",
        "for i in test:\n",
        "    avg_runtime += float(i[2].split(\" \")[2][:-1])\n",
        "    total += 1.0\n",
        "    \n",
        "    for metric in i:\n",
        "        if metric.split(\"=\")[0] == \" NDCG@100 \":\n",
        "            test_ndcg.append(float(metric.split('=')[1].split(' ')[1]))\n",
        "        if metric.split(\"=\")[0] == \" loss \":\n",
        "            test_loss.append(float(metric.split(\"=\")[1].split(' ')[1]))\n",
        "\n",
        "fig, ax1 = plt.subplots(figsize=(12, 5))\n",
        "ax1.set_title(hyper_params[\"project_name\"],fontweight=\"bold\", size=20)\n",
        "ax1.plot(test_ndcg, 'b-')\n",
        "ax1.set_xlabel('Epochs', fontsize = 20.0)\n",
        "ax1.set_ylabel('NDCG@100', color='b', fontsize = 20.0)\n",
        "ax1.tick_params('y', colors='b')\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(test_loss, 'r--')\n",
        "ax2.set_ylabel('Loss', color='r')\n",
        "ax2.tick_params('y', colors='r')\n",
        "\n",
        "fig.tight_layout()\n",
        "if not os.path.isdir(\"saved_plots/\"):\n",
        "    os.mkdir(\"saved_plots/\")\n",
        "fig.savefig(\"saved_plots/learning_curve_\" + hyper_params[\"project_name\"] + \".pdf\")\n",
        "plt.show()\n",
        "\n",
        "# Checking metrics for the test set on best saved model\n",
        "with open(hyper_params['model_file_name'], 'rb') as f:\n",
        "    model = torch.load(f)\n",
        "metrics, len_to_ndcg_at_100_map = evaluate(model, criterion, test_reader, hyper_params, False)\n",
        "\n",
        "# Plot sequence length vs NDCG@100 graph\n",
        "plot_len_vs_ndcg(len_to_ndcg_at_100_map)\n",
        "\n",
        "string = \"\"\n",
        "for m in metrics:\n",
        "    string += \" | \" + m + ' = ' + str(metrics[m])\n",
        "\n",
        "ss  = '=' * 89\n",
        "ss += '\\n| End of training'\n",
        "ss += string + \" (TEST)\"\n",
        "ss += '\\n'\n",
        "ss += '=' * 89\n",
        "file_write(hyper_params['log_file'], ss)\n",
        "print(\"average runtime per epoch =\", round(avg_runtime / float(total), 4), \"s\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Started reading data file\n",
            "Data Files loaded!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 71062/429847 [00:00<00:00, 710617.29it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "num_users:4525, len data_train:429847\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 429847/429847 [00:00<00:00, 486452.70it/s]\n",
            "100%|██████████| 57499/57499 [00:00<00:00, 740873.15it/s]\n",
            "100%|██████████| 14742/14742 [00:00<00:00, 744341.27it/s]\n",
            "  0%|          | 0/54306 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "num_users:748, len data_train:57499\n",
            "num_users:748, len data_train:54306\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 54306/54306 [00:00<00:00, 753182.26it/s]\n",
            "100%|██████████| 13970/13970 [00:00<00:00, 733668.40it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Simulation run on: 2021-05-28 12:14:25.606174\n",
            "\n",
            "\n",
            "Data reading complete!\n",
            "Number of train batches: 4525\n",
            "Number of validation batches:  748\n",
            "Number of test batches:  748\n",
            "Total Items: 3478\n",
            "\n",
            "SENDING MODEL TO CUDA...\n",
            "Model(\n",
            "  (encoder): Encoder(\n",
            "    (linear1): MobiusLinear(\n",
            "      , hyperbolic_bias=True\n",
            "      (ball): PoincareBall manifold\n",
            "    )\n",
            "    (activation): Tanh()\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (linear1): MobiusLinear(\n",
            "      , hyperbolic_bias=True\n",
            "      (ball): PoincareBall manifold\n",
            "    )\n",
            "    (linear2): MobiusLinear(\n",
            "      , hyperbolic_bias=True\n",
            "      (ball): PoincareBall manifold\n",
            "    )\n",
            "    (activation): Tanh()\n",
            "  )\n",
            "  (item_embed): LookupEmbedding(\n",
            "    (manifold): PoincareBall manifold\n",
            "  )\n",
            "  (gru): GRU(128, 100, batch_first=True)\n",
            "  (hygru): MobiusGRU(\n",
            "    128, 100, 1, bias=True, hyperbolic_input=False, hyperbolic_hidden_state0=True, c=1.0\n",
            "    (ball): PoincareBall manifold\n",
            "    (weight_ih): ParameterList(  (0): Parameter containing: [torch.cuda.FloatTensor of size 300x128 (GPU 0)])\n",
            "    (weight_hh): ParameterList(  (0): Parameter containing: [torch.cuda.FloatTensor of size 300x100 (GPU 0)])\n",
            "    (bias): ParameterList(  (0): Parameter containing: [torch.cuda.FloatTensor of size 3x100 (GPU 0)])\n",
            "  )\n",
            "  (linear1): MobiusLinear(\n",
            "    , hyperbolic_bias=True\n",
            "    (ball): PoincareBall manifold\n",
            "  )\n",
            "  (tanh): Tanh()\n",
            ")\n",
            "\n",
            "Model Built!\n",
            "Starting Training...\n",
            "\n",
            "| epoch   1 |  1000/ 4525 batches | ms/batch 122.75 | loss 746.8703\n",
            "Exiting from training early\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-21d071c4bdbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;31m# Checking metrics for the test set on best saved model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyper_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_file_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_to_ndcg_at_100_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyper_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'saved_models/colab_model_optimizer_radam_weight_decay_0.005_loss_type_next_k_item_embed_size_128_rnn_size_100_latent_size_32.pt'"
          ]
        }
      ]
    }
  ]
}